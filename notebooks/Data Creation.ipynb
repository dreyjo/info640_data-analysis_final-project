{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "historic-forestry",
   "metadata": {},
   "source": [
    "## Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "inside-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#requests allows us to get htnml pages from ACM\n",
    "import requests\n",
    "\n",
    "#then beautoful soup will help us parse the requested html information and\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#import regex\n",
    "import re\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "liquid-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling in Data for FAT 2019 proceedings:\n",
    "\n",
    "#ACM Proceedings Link:\n",
    "fat19 = \"https://dl.acm.org/doi/proceedings/10.1145/3287560\"\n",
    "#fat20 = \"https://dl.acm.org/doi/proceedings/10.1145/3351095\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-cotton",
   "metadata": {},
   "source": [
    "## Step 1 - use requests to get the url with the search and check server status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "female-honduras",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "Something is wrong\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(fat19)\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "if r.status_code == 200:\n",
    "    print(\"Sever Access is a go!\")\n",
    "else:\n",
    "    print(r.status_code)\n",
    "    print(\"Something is wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-replica",
   "metadata": {},
   "source": [
    "## Step 2 - get DOIs and put in an empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crazy-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi=[]\n",
    "#making a variable to hold the paper url as a substring\n",
    "substring = 'https://doi.org'\n",
    "links = soup.find_all('a', href=True)\n",
    "#for u in url:\n",
    "for a in links:\n",
    "    if re.search(substring,a['href']):\n",
    "        doi.append(a['href'])\n",
    "#Now doi holds a list of urls for all the papers we want/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-balloon",
   "metadata": {},
   "source": [
    "## Step 3 - writing function to get titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "transsexual-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(list):\n",
    "    t = []\n",
    "    for x in list:\n",
    "        #Here r and soup are local variables, so what assign them is only valid within the function!\n",
    "        r=requests.get(x)\n",
    "        soup = BeautifulSoup(r.text,'html.parser')\n",
    "        ttl=soup.find('h1').get_text()\n",
    "        t.append(ttl)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "motivated-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "tl=get_titles(doi)\n",
    "print(tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-permission",
   "metadata": {},
   "source": [
    "## Step 4 - writing function to get abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "champion-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstracts(list):\n",
    "    a = []\n",
    "    for x in list:\n",
    "        r=requests.get(x)\n",
    "        soup = BeautifulSoup(r.text,'html.parser')\n",
    "        abs=soup.find(class_='abstractSection abstractInFull').get_text()\n",
    "        a.append(abs)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cordless-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "ab=get_abstracts(doi)\n",
    "print(ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-import",
   "metadata": {},
   "source": [
    "## Step 5-6: (eventually) writing a function to get writers and references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "celtic-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step5: Writing function to get writers\n",
    "# def get_authors(list):\n",
    "#     wr = []\n",
    "#     for x in list:\n",
    "#         r=requests.get(x)\n",
    "#         soup = BeautifulSoup(r.text,'html.parser')\n",
    "#         auth=soup.find('span', class_=\"loa__author-name\")\n",
    "#             for a in auth:\n",
    "#                 writers=soup.find('span').get_text()\n",
    "#                 wr.append(writers)\n",
    "#     return wr\n",
    "#\n",
    "# w=get_authors(doi)\n",
    "# #print(w)\n",
    "\n",
    "#Step6: Writing function to get references\n",
    "#rf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-supply",
   "metadata": {},
   "source": [
    "## Step 7: Create dataframe using pandas and save as csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(tl,ab))\n",
    "df = pd.DataFrame(data, columns=['title', 'abstract'])\n",
    "df.to_csv(\"data_creation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
